{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mspatke/MLflow-Deep-Learning-UseCase/blob/main/MLFlow_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e4w-SC0wW8y",
        "outputId": "21ef9a3a-83be-4d12-b2e9-f53c0fbaf21c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-1.24.0-py3-none-any.whl (16.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.5 MB 160 kB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 38.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting docker>=4.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 45.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow) (21.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.32)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.2)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2018.9)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (4.11.2)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.16.4.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.19.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (1.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->mlflow) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mlflow) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mlflow) (2.8.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.13.1)\n",
            "Building wheels for collected packages: databricks-cli\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.16.4-py3-none-any.whl size=106877 sha256=2ba0613a27ed7f080d8894469c1dd235ce14948e1932ef9161de773b3b601a9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/a1/6d/fa1d22ea25ed8593887437fe1c7e00f6ef307fc240ccd4dc5c\n",
            "Successfully built databricks-cli\n",
            "Installing collected packages: smmap, websocket-client, Mako, gitdb, querystring-parser, pyyaml, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, alembic, mlflow\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.6 databricks-cli-0.16.4 docker-5.0.3 gitdb-4.0.9 gitpython-3.1.27 gunicorn-20.1.0 mlflow-1.24.0 prometheus-flask-exporter-0.19.0 pyyaml-6.0 querystring-parser-1.2.4 smmap-5.0.0 websocket-client-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MOaIWQFKnlZR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR #step learning rate\n",
        "from torchvision import datasets, transforms\n",
        "import mlflow\n",
        "import mlflow.pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BjvRDsc9nlZU"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    EPOCHS = 10\n",
        "    BATCH_SIZE =32\n",
        "    LR = 0.01\n",
        "    DEVICE= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    GAMMA = 0.7\n",
        "    SEED = 42\n",
        "    LOG_INTERVAL = 10\n",
        "    TEST_BATCH_SIZE = 1000\n",
        "    DRY_RUN = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config()"
      ],
      "metadata": {
        "id": "lQpiXIx6ocVO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(config.SEED)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,32,3,1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3,1)\n",
        "    self.dropout1 = nn.Dropout(0.25)\n",
        "    self.dropout2 = nn.Dropout(0.5)\n",
        "    self.fc1=nn.Linear(9216,128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self , x):\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "   \n",
        "    x = F.max_pool2d(x,2)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    x=F.relu(x)\n",
        "    x=self.dropout2(x)\n",
        "\n",
        "    x=self.fc2(x)\n",
        "\n",
        "    #output = F.log_softmax(x, dim=1)\n",
        "\n",
        "    return x      "
      ],
      "metadata": {
        "id": "4x85gzHsocRv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_(config, model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model.forward(data)\n",
        "    loss = F.cross_entropy(pred, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % config.LOG_INTERVAL == 0:\n",
        "      print(f\"train epoch: {epoch}[{batch_idx * len(data)}/{len(train_loader.dataset)} ({100.0 * batch_idx/len(train_loader):.0f})]\\t Loss: {loss.item():.6f}\")\n",
        "\n",
        "      if config.DRY_RUN:\n",
        "        break"
      ],
      "metadata": {
        "id": "eMH9Zl4qocOu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "  pass"
      ],
      "metadata": {
        "id": "tHm5iehCocId"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(config.SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9icC2ZJMoXeY",
        "outputId": "529eefa9-b5d6-4b42-c3c5-16d111a0086b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f23aa3fe530>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_kwargs = {\"batch_size\": config.BATCH_SIZE}\n",
        "test_kwargs = {\"batch_size\": config.TEST_BATCH_SIZE}"
      ],
      "metadata": {
        "id": "QcvhXjbTuOT1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if config.DEVICE ==\"cuda\":\n",
        "  cuda_kwargs = {\"num_workers\":1, \"pin_memory\":True, \"shuffle\":True}\n",
        "  train_kwargs.update(cuda_kwargs)\n",
        "  test_kwargs.update(cuda_kwargs)"
      ],
      "metadata": {
        "id": "xYiT78TsuZZA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans = transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        ")"
      ],
      "metadata": {
        "id": "Bd-vkA4huyDY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = datasets.MNIST(\"../data\", train = True , download= True, transform=trans)\n",
        "test  = datasets.MNIST(\"../data\", train=False, download=True, transform= trans)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, **train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(test, **test_kwargs)"
      ],
      "metadata": {
        "id": "t8NcuvMzu-2l"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "i1sT0tqV2LsJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet().to(config.DEVICE)\n",
        "scripted_model = torch.jit.script(model)\n",
        "print(scripted_model)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config.LR)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=config.GAMMA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inm4Clcsvojy",
        "outputId": "d900c18d-8269-46bd-a819-29a2831374f7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RecursiveScriptModule(\n",
            "  original_name=ConvNet\n",
            "  (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
            "  (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
            "  (dropout1): RecursiveScriptModule(original_name=Dropout)\n",
            "  (dropout2): RecursiveScriptModule(original_name=Dropout)\n",
            "  (fc1): RecursiveScriptModule(original_name=Linear)\n",
            "  (fc2): RecursiveScriptModule(original_name=Linear)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_loader:\n",
        "  print(i[0].shape, i[1].shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JhIGhrMwW0t",
        "outputId": "1ca83090-6f26-4872-9153-ff7383d183f8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "QWvflv5S0cOZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "\n",
        "for epoch in range(1,config.EPOCHS + 1):\n",
        "  train_(config, scripted_model, config.DEVICE, train_loader, optimizer, epoch)\n",
        "  scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IUQhpXGwi2_",
        "outputId": "01f7b4ac-75a8-48de-9a47-044d0229605f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train epoch: 1[0/60000 (0)]\t Loss: 2.305307\n",
            "train epoch: 2[0/60000 (0)]\t Loss: 6.217451\n",
            "train epoch: 3[0/60000 (0)]\t Loss: 3.385877\n",
            "train epoch: 4[0/60000 (0)]\t Loss: 2.220319\n",
            "train epoch: 5[0/60000 (0)]\t Loss: 2.266742\n",
            "train epoch: 6[0/60000 (0)]\t Loss: 2.323485\n",
            "train epoch: 7[0/60000 (0)]\t Loss: 2.276761\n",
            "train epoch: 8[0/60000 (0)]\t Loss: 2.296962\n",
            "train epoch: 9[0/60000 (0)]\t Loss: 2.296360\n",
            "train epoch: 10[0/60000 (0)]\t Loss: 2.264648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with mlflow.start_run() as run:\n",
        "  mlflow.pytorch.log_model(model, \"model\")\n",
        "  model_path = mlflow.get_artifact_uri(\"model\")\n",
        "  loaded_torch_model = mlflow.pytorch.load_model(model_path)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    test_datapoints, test_target = next(iter(test_loader))\n",
        "    pred = model(test_datapoints[0].reshape((1,1,28,28)).to(config.DEVICE))\n",
        "    actual = test_target[0].item()\n",
        "    predicted = torch.argmax(pred).item()\n",
        "    print(f\"actual:{actual}, prdicted :{predicted}\")"
      ],
      "metadata": {
        "id": "4ly_88iCwqUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d51970d-9d9a-47b5-8c51-47274988c35a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022/03/13 14:57:01 WARNING mlflow.utils.requirements_utils: Found torch version (1.10.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torch==1.10.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2022/03/13 14:57:07 WARNING mlflow.utils.requirements_utils: Found torch version (1.10.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torch==1.10.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual:2, prdicted :6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2hrwEphi7eXc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "041b736c206caa8195d500d881dbb3bcede296840cbb348f5cc00a1cceaa64a9"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 (conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "MLFlow-MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}